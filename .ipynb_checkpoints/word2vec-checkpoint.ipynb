{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "MINIMUM_SENTENCE_LENGTH = 3\n",
    "\n",
    "input_file_name=\"/mnt/data/test_data/parsed_namuwiki.txt\"\n",
    "output_file_name=\"/mnt/data/test_data/korean_sentences_for_word2vec.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_hangul = re.compile('[^ ㄱ-ㅣ가-힣|.]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "ex_split_sentence = ['',' ']\n",
    "def map_hangul(str):  #한글만 추출하는 메소드\n",
    "    str = str.replace('_',' ')\n",
    "    str = ex_hangul.sub('',str)\n",
    "    str = str.replace('  ',' ')\n",
    "    return str\n",
    "\n",
    "def split_sentence(str): #마침표로 문장을 나누고, 빈 문장을 제거하는 메소드\n",
    "    sentence_arr = str.split('.')\n",
    "    return list(filter(lambda x: x not in ex_split_sentence, sentence_arr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100000\n",
      "step: 200000\n",
      "step: 300000\n",
      "step: 400000\n",
      "step: 500000\n",
      "step: 600000\n",
      "step: 700000\n",
      "step: 800000\n",
      "step: 900000\n",
      "step: 1000000\n",
      "step: 1100000\n",
      "step: 1200000\n",
      "step: 1300000\n",
      "step: 1400000\n",
      "step: 1500000\n",
      "step: 1600000\n",
      "step: 1700000\n",
      "step: 1800000\n",
      "step: 1900000\n",
      "step: 2000000\n",
      "step: 2100000\n",
      "step: 2200000\n",
      "step: 2300000\n",
      "step: 2400000\n",
      "step: 2500000\n",
      "step: 2600000\n",
      "step: 2700000\n",
      "step: 2800000\n",
      "step: 2900000\n",
      "step: 3000000\n",
      "step: 3100000\n",
      "step: 3200000\n",
      "step: 3300000\n",
      "step: 3400000\n",
      "step: 3500000\n",
      "step: 3600000\n",
      "step: 3700000\n",
      "step: 3800000\n",
      "step: 3900000\n",
      "step: 4000000\n",
      "step: 4100000\n",
      "step: 4200000\n",
      "step: 4300000\n",
      "step: 4400000\n",
      "step: 4500000\n",
      "step: 4600000\n",
      "step: 4700000\n",
      "step: 4800000\n",
      "step: 4900000\n",
      "step: 5000000\n",
      "step: 5100000\n",
      "step: 5200000\n",
      "step: 5300000\n",
      "step: 5400000\n",
      "step: 5500000\n",
      "step: 5600000\n",
      "step: 5700000\n",
      "step: 5800000\n",
      "step: 5900000\n",
      "step: 6000000\n",
      "step: 6100000\n",
      "step: 6200000\n",
      "step: 6300000\n",
      "step: 6400000\n",
      "step: 6500000\n",
      "step: 6600000\n",
      "step: 6700000\n",
      "step: 6800000\n",
      "step: 6900000\n",
      "step: 7000000\n",
      "step: 7100000\n",
      "step: 7200000\n",
      "step: 7300000\n",
      "step: 7400000\n",
      "step: 7500000\n",
      "step: 7600000\n",
      "step: 7700000\n",
      "step: 7800000\n",
      "step: 7900000\n",
      "step: 8000000\n",
      "step: 8100000\n",
      "step: 8200000\n",
      "step: 8300000\n",
      "step: 8400000\n",
      "step: 8500000\n",
      "step: 8600000\n",
      "step: 8700000\n",
      "step: 8800000\n",
      "step: 8900000\n",
      "step: 9000000\n",
      "step: 9100000\n",
      "step: 9200000\n",
      "step: 9300000\n",
      "step: 9400000\n",
      "step: 9500000\n",
      "step: 9600000\n",
      "step: 9700000\n",
      "step: 9800000\n",
      "step: 9900000\n",
      "step: 10000000\n",
      "step: 10100000\n",
      "step: 10200000\n",
      "step: 10300000\n",
      "step: 10400000\n",
      "step: 10500000\n",
      "step: 10600000\n",
      "step: 10700000\n",
      "step: 10800000\n",
      "step: 10900000\n",
      "step: 11000000\n",
      "step: 11100000\n",
      "step: 11200000\n",
      "step: 11300000\n"
     ]
    }
   ],
   "source": [
    "#문장 전처리\n",
    "import time\n",
    "start = int(time.time())\n",
    "\n",
    "twitter_nlp = Twitter()\n",
    "output_file = open(output_file_name, \"a\")\n",
    "index = 0\n",
    "\n",
    "with open(input_file_name, \"r\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "\n",
    "            index += 1\n",
    "            if index % 100000 == 0:\n",
    "                print('step:',index)\n",
    "\n",
    "            if index < 8818461:\n",
    "                continue\n",
    "\n",
    "            tmp_sentences = split_sentence(map_hangul(line)) #한글 추출, 라인 split\n",
    "            for sentence in tmp_sentences:\n",
    "                tmp_noun_arr = twitter_nlp.nouns(sentence) #명사 추출\n",
    "                if len(tmp_noun_arr) > MINIMUM_SENTENCE_LENGTH:\n",
    "                    output_file.write(' '.join(tmp_noun_arr)+'\\n')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "output_file.close()\n",
    "end = int(time.time())\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = \"가.나.다\"\n",
    "print(a.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#word2vec 학습\n",
    "\n",
    "# model = gensim.models.Word2Vec(size=300, window=5, min_count=50, workers=2)\n",
    "# model.build_vocab(sentence_noun_arr)\n",
    "# model.train(sentence_noun_arr)\n",
    "# model.save('dict_data/w2v_model_wiki_kor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.wv.similarity('미국', '일본'))\n",
    "print(model.wv.most_similar(positive=['문재인', '박근혜'], negative=['노무현']))\n",
    "print(model.wv.doesnt_match(twitter.nouns('박근혜는 가나다를 좋아한다')))\n",
    "# model.score([twitter.nouns('박근혜는 가나다를 좋아한다')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model = gensim.models.Word2Vec.load('dict_data/w2v_model_wiki_kor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(new_model.wv.similarity('미국', '일본'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
